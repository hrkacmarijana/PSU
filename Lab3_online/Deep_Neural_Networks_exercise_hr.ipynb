{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Uvod #\n","\n","U vodiču smo vidjeli kako izgraditi duboke neuronske mreže slaganjem slojeva unutar `Sekvencijalnog` modela. Dodavanjem *aktivacijske funkcije* nakon skrivenih slojeva, mreži smo dali mogućnost da nauči složenije (nelinearne) odnose u podacima.\n","\n","U ovim ćete vježbama izgraditi neuronsku mrežu s nekoliko skrivenih slojeva i zatim istražiti neke aktivacijske funkcije izvan ReLU-a. Pokrenite ovu sljedeću ćeliju da sve postavite!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","\n","# Setup plotting\n","import matplotlib.pyplot as plt\n","\n","plt.style.use('seaborn-v0_8-whitegrid')\n","# Set Matplotlib defaults\n","plt.rc('figure', autolayout=True)\n","plt.rc('axes', labelweight='bold', labelsize='large',\n","       titleweight='bold', titlesize=18, titlepad=10)\n"]},{"cell_type":"markdown","metadata":{},"source":["U skupu podataka *Concrete* vaš je zadatak predvidjeti tlačnu čvrstoću betona proizvedenog prema različitim recepturama.\n","\n","Pokrenite sljedeću ćeliju koda bez promjena za učitavanje skupa podataka."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","concrete = pd.read_csv('./input/concrete.csv')\n","concrete.head()"]},{"cell_type":"markdown","metadata":{},"source":["# 1) Ulazni oblik #\n","\n","Cilj za ovaj zadatak je stupac `'CompressiveStrength'`. Preostali stupci su značajke koje ćemo koristiti kao ulazne podatke.\n","\n","Kakav bi bio ulazni oblik za ovaj skup podataka?"]},{"cell_type":"code","execution_count":null,"metadata":{"lines_to_next_cell":2},"outputs":[],"source":["# YOUR CODE HERE\n","input_shape = ____\n"]},{"cell_type":"markdown","metadata":{},"source":["# 2) Definirajte model sa skrivenim slojevima #\n","\n","Sada izradite model s tri skrivena sloja, od kojih svaki ima 512 jedinica i ReLU aktivaciju. Svakako uključite izlazni sloj od jedne jedinice i bez aktivacije, a također i `input_shape` kao argument prvom sloju."]},{"cell_type":"code","execution_count":null,"metadata":{"lines_to_next_cell":0},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# YOUR CODE HERE\n","model = ____"]},{"cell_type":"markdown","metadata":{},"source":["# 3) Aktivacijski slojevi #\n","\n","Istražimo neke funkcije aktivacije.\n","\n","Uobičajeni način pripajanja aktivacijske funkcije sloju `Dense` jest uključiti je kao dio definicije s argumentom `activation`. Ponekad ćete ipak htjeti staviti neki drugi sloj između sloja `Dense` i njegove aktivacijske funkcije. (Vidjet ćemo primjer ovoga kasnije.) U ovom slučaju, možemo definirati aktivaciju u vlastitom sloju `Aktivacija`, ovako:\n","\n","```\n","layers.Dense(units=8),\n","layers.Activation('relu')\n","```\n","\n","Ovo je potpuno ekvivalentno uobičajenom načinu: `layers.Dense(units=8, activation='relu')`.\n","\n","Prepišite sljedeći model tako da svaka aktivacija bude u vlastitom sloju `Activation`."]},{"cell_type":"code","execution_count":null,"metadata":{"lines_to_next_cell":0},"outputs":[],"source":["### YOUR CODE HERE: rewrite this to use activation layers\n","model = keras.Sequential([\n","    layers.Dense(32, activation='relu', input_shape=[8]),\n","    layers.Dense(32, activation='relu'),\n","    layers.Dense(1),\n","])\n"]},{"cell_type":"markdown","metadata":{},"source":["# Izborno: Alternative za ReLU #\n","\n","Postoji cijela obitelj varijanti aktivacije `'relu'` -- `'elu'`, `'selu'`, i `'swish'`, između ostalih -- koje sve možete koristiti u Kerasu. Ponekad će jedna aktivacija biti bolja od druge na određenom zadatku, pa biste mogli razmisliti o eksperimentiranju s aktivacijama dok razvijate model. ReLU aktivacija ima tendenciju da dobro funkcionira na većini problema, tako da je dobra za početak.\n","\n","Pogledajmo grafikone nekih od njih. Promijenite aktivaciju iz `'relu'` u jednu od ostalih gore navedenih. Zatim pokrenite ćeliju da vidite grafikon. (Provjerite [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/activations) za više ideja.)"]},{"cell_type":"code","execution_count":null,"metadata":{"lines_to_next_cell":0},"outputs":[],"source":["# YOUR CODE HERE: Change 'relu' to 'elu', 'selu', 'swish'... or something else\n","activation_layer = layers.Activation('relu')\n","\n","x = tf.linspace(-3.0, 3.0, 100)\n","y = activation_layer(x) # once created, a layer is callable just like a function\n","\n","plt.figure(dpi=100)\n","plt.plot(x, y)\n","plt.xlim(-3, 3)\n","plt.xlabel(\"Input\")\n","plt.ylabel(\"Output\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Dalje #\n","\n","Sada prijeđite na sljedeću lekciju [**naučite kako istrenirati neuralnu mrežu**](Stochastic_Gradient_Descent_hr.ipynb) sa stohastičkim gradijentnim spuštanjem."]}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","formats":"ipynb"},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":829369,"sourceId":1480608,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
