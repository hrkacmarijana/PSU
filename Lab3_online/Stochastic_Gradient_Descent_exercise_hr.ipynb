{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorflow import keras\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","import numpy as np\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from matplotlib import animation, rc\n","rc('animation', html='html5')\n","plt.style.use('seaborn-v0_8-whitegrid')\n","\n","# NUM_EXAMPLES = 256\n","# BATCH_SIZE = 8\n","# STEPS = 50 # actually steps\n","# LR = 0.1\n","\n","\n","def animate_sgd(num_examples, batch_size, steps, learning_rate,\n","                true_w=3.0, true_b=2.0, seed=0):\n","    # Define model\n","    class Model(object):\n","        def __init__(self, w_init=-1.0, b_init=-1.0):\n","            self.W = tf.Variable(w_init)\n","            self.b = tf.Variable(b_init)\n","\n","        def __call__(self, x):\n","            return self.W * x + self.b\n","            \n","    def loss(target_y, predicted_y):\n","        return tf.reduce_mean(tf.square(target_y - predicted_y))\n","\n","    def train(model, inputs, outputs, learning_rate):\n","        with tf.GradientTape() as t:\n","            current_loss = loss(outputs, model(inputs))\n","            dW, db = t.gradient(current_loss, [model.W, model.b])\n","            model.W.assign_sub(learning_rate * dW)\n","            model.b.assign_sub(learning_rate * db)\n","    # Data\n","    inputs  = tf.random.normal(shape=[num_examples], seed=seed)\n","    noise   = tf.random.normal(shape=[num_examples], seed=seed+1)\n","    outputs = inputs * true_w + true_b + noise\n","    ds = (tf.data.Dataset\n","          .from_tensor_slices((inputs, outputs))\n","          .shuffle(1000, seed=seed)\n","          .batch(batch_size)\n","          .repeat())\n","    ds = iter(ds)\n","    model = Model()\n","    # Collect the history of W-values and b-values to plot later\n","    Ws, bs, xs, ys, ls = [], [], [], [], []\n","    # Construct plot\n","    fig = plt.figure(dpi=100, figsize=(8, 3))\n","\n","    # Regression Line\n","    ax1 = fig.add_subplot(131)\n","    ax1.set_title(\"Fitted Line\")\n","    ax1.set_xlabel(\"x\")\n","    ax1.set_ylabel(\"y\")\n","    ax1.set_xlim(-3, 2.5)\n","    ax1.set_ylim(-8, 11)\n","    p10, = ax1.plot(inputs, outputs, 'r.', alpha=0.1) # full dataset\n","    p11, = ax1.plot([], [], 'C3.') # batch, color Red\n","    p12, = ax1.plot([], [], 'k') # fitted line, color Black\n","\n","    # Loss\n","    ax2 = fig.add_subplot(132)\n","    ax2.set_title(\"Training Loss\")\n","    ax2.set_xlabel(\"Batches Seen\")\n","    ax2.set_xlim(0, steps)\n","    ax2.set_ylim(0, 40)\n","    p20, = ax2.plot([], [], 'C0') # color Blue\n","\n","    # Weights\n","    ax3 = fig.add_subplot(133)\n","    ax3.set_title(\"Weights\")\n","    ax3.set_xlabel(\"Batches Seen\")\n","    ax3.set_xlim(0, steps)     # \n","    ax3.set_ylim(-2, 4)\n","    ax3.plot(range(steps), [true_w for _ in range(steps)], 'C5--')\n","    ax3.plot(range(steps), [true_b for _ in range(steps)], 'C8--')\n","    p30, = ax3.plot([], [], 'C5') # W color Brown\n","    p30.set_label('W')\n","    p31, = ax3.plot([], [], 'C8') # b color Green\n","    p31.set_label('b')\n","    ax3.legend()\n","\n","    fig.tight_layout()\n","\n","    def init():\n","        return [p10]\n","\n","    def update(epoch):\n","        x, y = next(ds)\n","        y_pred = model(x)\n","        current_loss = loss(y, y_pred)\n","          \n","        Ws.append(model.W.numpy())\n","        bs.append(model.b.numpy())\n","        xs.append(x.numpy())\n","        ys.append(y_pred.numpy())\n","        ls.append(current_loss.numpy())\n","        p11.set_data(x.numpy(), y.numpy())\n","        inputs = tf.linspace(-3.0, 2.5, 30)\n","        p12.set_data(inputs, Ws[-1]*inputs + bs[-1])\n","        p20.set_data(range(epoch), ls)\n","        p30.set_data(range(epoch), Ws)\n","        p31.set_data(range(epoch), bs)\n","\n","        train(model, x, y, learning_rate=learning_rate)\n","        #   print('Epoch %2d: W=%1.2f b=%1.2f, loss=%2.5f' %\n","        #         (epoch, Ws[-1], bs[-1], current_loss))\n","        \n","        return p11, p12, p20\n","\n","    ani = animation.FuncAnimation(\n","        fig,\n","        update,\n","        frames=range(1, steps),\n","        init_func=init,\n","        blit=True,\n","        interval=100,\n","    )\n","    plt.close()\n","    return ani"]},{"cell_type":"markdown","metadata":{},"source":["# Uvod #\n","\n","U ovoj ćete vježbi uvježbati neuronsku mrežu na skupu podataka *Fuel Economy*, a zatim istražiti učinak stope učenja i veličine serije na SGD.\n","\n","Kada budete spremni, pokrenite ovu sljedeću ćeliju da sve postavite!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Setup plotting\n","import matplotlib.pyplot as plt\n","#from learntools.deep_learning_intro.dltools import animate_sgd\n","plt.style.use('seaborn-v0_8-whitegrid')\n","# Set Matplotlib defaults\n","plt.rc('figure', autolayout=True)\n","plt.rc('axes', labelweight='bold', labelsize='large',\n","       titleweight='bold', titlesize=18, titlepad=10)\n","plt.rc('animation', html='html5')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["U skupu podataka *Fuel Economy* vaš je zadatak predvidjeti potrošnju goriva automobila s obzirom na značajke poput vrste motora ili godine proizvodnje.\n","\n","Prvo učitajte skup podataka pokretanjem donje ćelije."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import make_column_transformer, make_column_selector\n","from sklearn.model_selection import train_test_split\n","\n","fuel = pd.read_csv('./input/fuel.csv')\n","\n","X = fuel.copy()\n","# Remove target\n","y = X.pop('FE')\n","\n","preprocessor = make_column_transformer(\n","    (StandardScaler(),\n","     make_column_selector(dtype_include=np.number)),\n","    (OneHotEncoder(sparse_output=False),\n","     make_column_selector(dtype_include=object)),\n",")\n","\n","X = preprocessor.fit_transform(X)\n","y = np.log(y) # log transform target instead of standardizing\n","\n","input_shape = [X.shape[1]]\n","print(\"Input shape: {}\".format(input_shape))"]},{"cell_type":"markdown","metadata":{},"source":["Ako želite, pogledajte podatke. Naš cilj u ovom slučaju je stupac `'FE'`, a preostali stupci su značajke."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Uncomment to see original data\n","fuel.head()\n","# Uncomment to see processed features\n","pd.DataFrame(X[:10,:]).head()"]},{"cell_type":"markdown","metadata":{},"source":["Pokrenite sljedeću ćeliju da definirate mrežu koju ćemo koristiti za ovaj zadatak."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","model = keras.Sequential([\n","    layers.Dense(128, activation='relu', input_shape=input_shape),\n","    layers.Dense(128, activation='relu'),    \n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(1),\n","])"]},{"cell_type":"markdown","metadata":{},"source":["# 1) Dodajte gubitak - loss i optimizator\n","\n","Prije treniranja mreže moramo definirati gubitak i optimizator koji ćemo koristiti. Koristeći metodu `compile` modela, dodajte `Adam` optimizator i `MAE` gubitak."]},{"cell_type":"code","execution_count":null,"metadata":{"lines_to_next_cell":0},"outputs":[],"source":["# YOUR CODE HERE\n","____\n"]},{"cell_type":"markdown","metadata":{},"source":["# 2) Treniranje Modela\n","\n","Nakon što definirate model i kompajlirate ga s gubitkom i optimizatorom, spremni ste za traniranje. Uvježbajte mrežu za 200 epoha s veličinom serije od 128. Ulazni podaci su \"X\" s ciljem \"y\"."]},{"cell_type":"code","execution_count":null,"metadata":{"lines_to_next_cell":0},"outputs":[],"source":["# YOUR CODE HERE\n","history = ____"]},{"cell_type":"markdown","metadata":{},"source":["Zadnji korak je pogledati krivulje gubitaka i procijeniti trening. Pokrenite donju ćeliju da dobijete dijagram gubitka treninga."]},{"cell_type":"code","execution_count":null,"metadata":{"lines_to_next_cell":0},"outputs":[],"source":["import pandas as pd\n","\n","history_df = pd.DataFrame(history.history)\n","# Start the plot at epoch 5. You can change this to get a different view.\n","history_df.loc[5:, ['loss']].plot();"]},{"cell_type":"markdown","metadata":{},"source":["# 3) Evaluirajte treniranje\n","\n","Da ste duže trenirali model, biste li očekivali da će se gubitak dodatno smanjiti?"]},{"cell_type":"markdown","metadata":{},"source":["Sa stopom učenja i veličinom serije, imate određenu kontrolu nad tim:\n","- Koliko dugo traje traniranje modela\n","- Koliko krivulje učenja imaju šuma\n","- Kako mali gubitak postaje\n","\n","Kako bismo bolje razumjeli ova dva parametra, pogledat ćemo linearni model, našu najjednostavniju neuronsku mrežu. Imajući samo jednu težinu i pristranost, lakše je vidjeti kakav učinak ima promjena parametra.\n","\n","Sljedeća će ćelija generirati animaciju poput one u prethodnoj bilježnici. Promijenite vrijednosti za \"learning_rate\", \"batch_size\" i \"num_examples\" (koliko podatkovnih točaka), a zatim pokrenite ćeliju. (Može potrajati trenutak ili dva.) Isprobajte sljedeće kombinacije ili isprobajte neke svoje:\n","\n","| `learning_rate` | `batch_size` | `num_examples` |\n","|-----------------|--------------|----------------|\n","| 0.05            | 32           | 256            |\n","| 0.05            | 2            | 256            |\n","| 0.05            | 128          | 256            |\n","| 0.02            | 32           | 256            |\n","| 0.2             | 32           | 256            |\n","| 1.0             | 32           | 256            |\n","| 0.9             | 4096         | 8192           |\n","| 0.99            | 4096         | 8192           |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# YOUR CODE HERE: Experiment with different values for the learning rate, batch size, and number of examples\n","learning_rate = 0.05\n","batch_size = 32\n","num_examples = 256\n","\n","animate_sgd(\n","    learning_rate=learning_rate,\n","    batch_size=batch_size,\n","    num_examples=num_examples,\n","    # You can also change these, if you like\n","    steps=50, # total training steps (batches seen)\n","    true_w=3.0, # the slope of the data\n","    true_b=2.0, # the bias of the data\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# 4) Stopa učenja i veličina serije\n","\n","Šro mislite, kakav je učinak imala promjena ovih parametara?"]},{"cell_type":"markdown","metadata":{},"source":["# Nastavi #\n","\n","Naučite kako [**poboljšati preformanse modela**](Overfitting_and_Underfitting_hr.ipynb) podešavanjem kapaciteta ili dodavanjem povratnog poziva za rano zaustavljanje."]}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","formats":"ipynb"},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":829369,"sourceId":1480608,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
